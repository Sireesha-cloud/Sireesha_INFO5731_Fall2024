{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sireesha-cloud/Sireesha_INFO5731_Fall2024/blob/main/INFO5731_Exercise_3_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdRwkJBn70nX"
      },
      "source": [
        "# **INFO5731 In-class Exercise 3**\n",
        "\n",
        "The purpose of this exercise is to explore various aspects of text analysis, including feature extraction, feature selection, and text similarity ranking.\n",
        "\n",
        "**Expectations**:\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "**Total points**: 40\n",
        "\n",
        "**Deadline**: This in-class exercise is due at the end of Friday, at 11:59 PM.\n",
        "\n",
        "**Late submissions will have a penalty of 10% of the marks for each day of late submission. , and no requests will be answered. Manage your time accordingly.**\n",
        "\n",
        "**Please check that the link you submitted can be opened and points to the correct assignment.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARqm7u6B70ne"
      },
      "source": [
        "## Question 1 (10 Points)\n",
        "Describe an interesting **text classification or text mining task** and explain what kind of features might be useful for you to build the machine learning model. List your features and explain why these features might be helpful. You need to list at least five different types of features. **Your dataset must be text.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAZj4PHB70nf"
      },
      "outputs": [],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Job Resume Classification entails sorting resumes into distinct employment positions or industries depending on the candidate's abilities, experience, and credentials.\n",
        "For example, resumes might be classed as \"Software Engineer,\" \"Data Scientist,\" \"Marketing Manager,\" or \"Sales Executive.\" This work can assist automate and speed up the recruiting process, allowing hiring managers to more easily match individuals to suitable job positions.\n",
        "\n",
        "To create a machine learning model for resume categorisation, we must first extract significant characteristics from the resume content itself. Here are five key aspects that will be beneficial for this task:\n",
        "\n",
        "1) Skills and Keywords:\n",
        "Description: Identify applicable abilities (e.g., Python, Java, project management, machine learning) and domain-specific keywords.\n",
        "Why is it useful: Skills and keywords are excellent markers of job fit. A résumé that mentions \"data analysis\" and \"Python\" is more likely to match a Data Scientist post, whereas \"marketing strategy\" and \"SEO\" would correlate to a Marketing Manager position. These keywords assist the model recognise the candidate's major competencies.\n",
        "\n",
        "2) Work Experience (Job Titles):\n",
        "Extract job titles from the candidate's prior employment (for example, \"Software Engineer,\" \"Data Analyst,\" and \"Marketing Coordinator\").\n",
        "Why is it useful: Job titles give valuable information about a candidate's professional past. The model can utilise job titles to match the resume to an appropriate category. A CV with the title \"Project Manager\" would be more appropriate for a management position.\n",
        "\n",
        "3) Education and Certifications:\n",
        "Description: Extract the educational background (\"Bachelor's in Computer Science,\" \"MBA\") and credentials (\"Certified Scrum Master,\" \"AWS Certified Solutions Architect\").\n",
        "Why is it useful: Educational degrees and certifications frequently demonstrate a candidate's topic competence and work readiness. A degree in Computer Science, for example, is more suited to software engineering, whilst an MBA is better suited to administrative employment.\n",
        "\n",
        "4) Years of Experience:\n",
        "Description: Extract the total number of years of professional experience the candidate has.\n",
        "Why it's useful: Seniority levels can be inferred from years of experience. A person with 10+ years of experience is more likely to be a senior-level professional or manager, while someone with 1-3 years of experience might be categorized for junior or entry-level roles.\n",
        "\n",
        "5)  Language Proficiency:\n",
        "Description: Identify the languages in which the individual is skilled (for example, English, Spanish, and Mandarin).\n",
        "Why is it useful: Some employment vocations or sectors may need proficiency in specific languages. For example, a CV citing Mandarin fluency may be classed as employment that need communication with Chinese-speaking clients or stakeholders. It can also be used for translation and localisation jobs.\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEUjBE6C70nf"
      },
      "source": [
        "## Question 2 (10 Points)\n",
        "Write python code to extract these features you discussed above. You can collect a few sample text data for the feature extraction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoQX5s4O70nf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8249a87b-a30e-4091-c168-b9a9ab3c99a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.8.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.19.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resume 1:\n",
            "Skills: ['Python', 'Java', 'Machine Learning', 'Cloud Computing', 'Data Analysis', 'AWS']\n",
            "Job Titles: ['XYZ Corp', 'Data Analysis', 'Bachelor', 'Computer Science', 'Stanford University']\n",
            "Education: ['Stanford University']\n",
            "Certifications: []\n",
            "Years of Experience: 5\n",
            "Language Proficiency: []\n",
            "\n",
            "\n",
            "Resume 2:\n",
            "Skills: ['SEO', 'Marketing']\n",
            "Job Titles: ['ABC Ltd. Expertise', 'Harvard Business School']\n",
            "Education: ['Harvard Business School']\n",
            "Certifications: []\n",
            "Years of Experience: 7\n",
            "Language Proficiency: ['English', 'Spanish']\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "!pip install spacy\n",
        "!pip install nltk\n",
        "!pip install pandas\n",
        "\n",
        "import spacy\n",
        "import re\n",
        "import nltk\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "resumes = [\n",
        "    \"\"\"\n",
        "    John Doe\n",
        "    Software Engineer with 5 years of experience in Python, Java, and software development.\n",
        "    Worked at XYZ Corp as a Senior Software Developer. Skilled in Machine Learning, Data Analysis, and Cloud Computing.\n",
        "    Holds a Bachelor's degree in Computer Science from Stanford University. Certified AWS Solutions Architect.\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    Jane Smith\n",
        "    Marketing Manager with 7 years of experience in digital marketing, SEO, and content strategy.\n",
        "    Managed a team of 5 at ABC Ltd. Expertise in market research, social media marketing, and brand management.\n",
        "    Holds an MBA from Harvard Business School. Fluent in Spanish and English.\n",
        "    \"\"\",\n",
        "]\n",
        "\n",
        "\n",
        "def extract_features(resume_text):\n",
        "\n",
        "    doc = nlp(resume_text)\n",
        "\n",
        "\n",
        "    keywords = [\"Python\", \"Java\", \"Machine Learning\", \"SEO\", \"Cloud Computing\", \"Marketing\", \"Data Analysis\", \"AWS\"]\n",
        "    extracted_skills = [kw for kw in keywords if kw in resume_text]\n",
        "\n",
        "\n",
        "    job_titles = []\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ == \"ORG\":\n",
        "            job_titles.append(ent.text)\n",
        "\n",
        "\n",
        "    education = []\n",
        "    certifications = []\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ == \"ORG\" and \"University\" in ent.text or \"School\" in ent.text:\n",
        "            education.append(ent.text)\n",
        "        if \"Certified\" in ent.text or \"Certification\" in ent.text:\n",
        "            certifications.append(ent.text)\n",
        "\n",
        "\n",
        "    years_of_experience = re.findall(r\"(\\d+) years of experience\", resume_text)\n",
        "    if years_of_experience:\n",
        "        years_of_experience = max(map(int, years_of_experience))\n",
        "    else:\n",
        "        years_of_experience = \"Unknown\"\n",
        "\n",
        "\n",
        "    languages = [\"English\", \"Spanish\", \"Mandarin\", \"French\", \"German\"]\n",
        "    language_proficiency = [lang for lang in languages if lang in resume_text]\n",
        "\n",
        "    return {\n",
        "        \"Skills\": extracted_skills,\n",
        "        \"Job Titles\": job_titles,\n",
        "        \"Education\": education,\n",
        "        \"Certifications\": certifications,\n",
        "        \"Years of Experience\": years_of_experience,\n",
        "        \"Language Proficiency\": language_proficiency\n",
        "    }\n",
        "\n",
        "\n",
        "for idx, resume in enumerate(resumes):\n",
        "    print(f\"Resume {idx + 1}:\")\n",
        "    features = extract_features(resume)\n",
        "    for feature, value in features.items():\n",
        "        print(f\"{feature}: {value}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oSK4soH70nf"
      },
      "source": [
        "## Question 3 (10 points):\n",
        "Use any of the feature selection methods mentioned in this paper \"Deng, X., Li, Y., Weng, J., & Zhang, J. (2019). Feature selection for text classification: A review. Multimedia Tools & Applications, 78(3).\"\n",
        "\n",
        "Select the most important features you extracted above, rank the features based on their importance in the descending order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CRuXfV570ng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfae1994-1dc4-47ac-9bac-bd1d92c18241"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   Feature  Chi2 Score   P-value\n",
            "1              skills_java       2.000  0.367879\n",
            "2               skills_seo       2.000  0.367879\n",
            "5                 cert_aws       2.000  0.367879\n",
            "9         language_spanish       2.000  0.367879\n",
            "0            skills_python       1.000  0.606531\n",
            "3     skills_data_analysis       1.000  0.606531\n",
            "4  skills_machine_learning       1.000  0.606531\n",
            "6             education_cs       1.000  0.606531\n",
            "7         years_experience       0.875  0.645649\n",
            "8         language_english       0.000  1.000000\n"
          ]
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "import pandas as pd\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Sample resumes and corresponding job roles (target variable)\n",
        "data = [\n",
        "    {\n",
        "        \"resume\": \"\"\"\n",
        "        John Doe\n",
        "        Software Engineer with 5 years of experience in Python, Java, and software development.\n",
        "        Worked at XYZ Corp as a Senior Software Developer. Skilled in Machine Learning, Data Analysis, and Cloud Computing.\n",
        "        Holds a Bachelor's degree in Computer Science from Stanford University. Certified AWS Solutions Architect.\n",
        "        \"\"\",\n",
        "        \"job_role\": \"Software Engineer\"\n",
        "    },\n",
        "    {\n",
        "        \"resume\": \"\"\"\n",
        "        Jane Smith\n",
        "        Marketing Manager with 7 years of experience in digital marketing, SEO, and content strategy.\n",
        "        Managed a team of 5 at ABC Ltd. Expertise in market research, social media marketing, and brand management.\n",
        "        Holds an MBA from Harvard Business School. Fluent in Spanish and English.\n",
        "        \"\"\",\n",
        "        \"job_role\": \"Marketing Manager\"\n",
        "    },\n",
        "    {\n",
        "        \"resume\": \"\"\"\n",
        "        Jack Brown\n",
        "        Data Scientist with 4 years of experience in Python, R, and machine learning algorithms.\n",
        "        Worked at DEF Inc. on building predictive models and data-driven solutions. Holds a Master's degree in Data Science from MIT.\n",
        "        \"\"\",\n",
        "        \"job_role\": \"Data Scientist\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Define features based on previously extracted features\n",
        "# For simplicity, we consider categorical features here\n",
        "resumes_data = pd.DataFrame([\n",
        "    {\"skills_python\": 1, \"skills_java\": 1, \"skills_seo\": 0, \"skills_data_analysis\": 1, \"skills_machine_learning\": 1,\n",
        "     \"cert_aws\": 1, \"education_cs\": 1, \"years_experience\": 5, \"language_english\": 1, \"language_spanish\": 0, \"job_role\": \"Software Engineer\"},\n",
        "\n",
        "    {\"skills_python\": 0, \"skills_java\": 0, \"skills_seo\": 1, \"skills_data_analysis\": 0, \"skills_machine_learning\": 0,\n",
        "     \"cert_aws\": 0, \"education_cs\": 0, \"years_experience\": 7, \"language_english\": 1, \"language_spanish\": 1, \"job_role\": \"Marketing Manager\"},\n",
        "\n",
        "    {\"skills_python\": 1, \"skills_java\": 0, \"skills_seo\": 0, \"skills_data_analysis\": 1, \"skills_machine_learning\": 1,\n",
        "     \"cert_aws\": 0, \"education_cs\": 1, \"years_experience\": 4, \"language_english\": 1, \"language_spanish\": 0, \"job_role\": \"Data Scientist\"}\n",
        "])\n",
        "\n",
        "# Encoding the target variable (job roles)\n",
        "label_encoder = LabelEncoder()\n",
        "resumes_data['job_role_encoded'] = label_encoder.fit_transform(resumes_data['job_role'])\n",
        "\n",
        "# Independent variables (features) and target variable (job role)\n",
        "X = resumes_data.drop(columns=['job_role', 'job_role_encoded'])\n",
        "y = resumes_data['job_role_encoded']\n",
        "\n",
        "# Perform Chi-Square test\n",
        "chi2_values, p_values = chi2(X, y)\n",
        "\n",
        "# Create a dataframe to rank features based on Chi-Square scores\n",
        "chi2_df = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Chi2 Score': chi2_values,\n",
        "    'P-value': p_values\n",
        "})\n",
        "\n",
        "# Sort by Chi2 score in descending order\n",
        "chi2_df = chi2_df.sort_values(by='Chi2 Score', ascending=False)\n",
        "\n",
        "print(chi2_df)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nZGAOwl70ng"
      },
      "source": [
        "## Question 4 (10 points):\n",
        "Write python code to rank the text based on text similarity. Based on the text data you used for question 2, design a query to match the most relevant docments. Please use the BERT model to represent both your query and the text data, then calculate the cosine similarity between the query and each text in your data. Rank the similary with descending order."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install scikit-learn\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Load BERT model and tokenizer from transformers library\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Function to get BERT embeddings for a given text\n",
        "def get_bert_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    # Use the mean of the last hidden state for embedding representation\n",
        "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "\n",
        "# Sample resumes data\n",
        "resumes = [\n",
        "    \"\"\"\n",
        "    John Doe\n",
        "    Software Engineer with 5 years of experience in Python, Java, and software development.\n",
        "    Worked at XYZ Corp as a Senior Software Developer. Skilled in Machine Learning, Data Analysis, and Cloud Computing.\n",
        "    Holds a Bachelor's degree in Computer Science from Stanford University. Certified AWS Solutions Architect.\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    Jane Smith\n",
        "    Marketing Manager with 7 years of experience in digital marketing, SEO, and content strategy.\n",
        "    Managed a team of 5 at ABC Ltd. Expertise in market research, social media marketing, and brand management.\n",
        "    Holds an MBA from Harvard Business School. Fluent in Spanish and English.\n",
        "    \"\"\"\n",
        "]\n",
        "\n",
        "# Query that we want to match the resumes with\n",
        "query = \"Looking for a Software Engineer with experience in Python, Java, and Machine Learning. Cloud computing experience preferred.\"\n",
        "\n",
        "# Get BERT embeddings for the query and each resume\n",
        "query_embedding = get_bert_embedding(query)\n",
        "resume_embeddings = [get_bert_embedding(resume) for resume in resumes]\n",
        "\n",
        "# Calculate cosine similarity between the query and each resume\n",
        "similarities = [cosine_similarity([query_embedding], [resume_embedding])[0][0] for resume_embedding in resume_embeddings]\n",
        "\n",
        "# Rank resumes by similarity (in descending order)\n",
        "ranked_indices = np.argsort(similarities)[::-1]\n",
        "\n",
        "# Display ranked resumes\n",
        "for idx in ranked_indices:\n",
        "    print(f\"Resume {idx + 1} (Similarity: {similarities[idx]:.4f}):\\n{resumes[idx]}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKGWxfDkyGrS",
        "outputId": "41ce6718-7801-4662-8c10-eeb8da6370b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resume 1 (Similarity: 0.8838):\n",
            "\n",
            "    John Doe\n",
            "    Software Engineer with 5 years of experience in Python, Java, and software development. \n",
            "    Worked at XYZ Corp as a Senior Software Developer. Skilled in Machine Learning, Data Analysis, and Cloud Computing. \n",
            "    Holds a Bachelor's degree in Computer Science from Stanford University. Certified AWS Solutions Architect.\n",
            "    \n",
            "\n",
            "Resume 2 (Similarity: 0.7768):\n",
            "\n",
            "    Jane Smith\n",
            "    Marketing Manager with 7 years of experience in digital marketing, SEO, and content strategy. \n",
            "    Managed a team of 5 at ABC Ltd. Expertise in market research, social media marketing, and brand management.\n",
            "    Holds an MBA from Harvard Business School. Fluent in Spanish and English.\n",
            "    \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mandatory Question"
      ],
      "metadata": {
        "id": "VEs-OoDEhTW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important: Reflective Feedback on this exercise**\n",
        "\n",
        "Please provide your thoughts and feedback on the exercises you completed in this assignment. Consider the following points in your response:\n",
        "\n",
        "Learning Experience: Describe your overall learning experience in working on extracting features from text data. What were the key concepts or techniques you found most beneficial in understanding the process?\n",
        "\n",
        "Challenges Encountered: Were there specific difficulties in completing this exercise?\n",
        "\n",
        "Relevance to Your Field of Study: How does this exercise relate to the field of NLP?\n",
        "\n",
        "**(Your submission will not be graded if this question is left unanswered)**\n",
        "\n"
      ],
      "metadata": {
        "id": "IUKC7suYhVl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "Learning experience: Working on resume categorisation has provided valuable expertise in using NLP approaches to extract relevant characteristics from text. Key concepts such as text preprocessing (noise removal, tokenisation, and lemmatisation), Named Entity Recognition (NER) for extracting job titles and degrees, and vectorisation techniques such as Bag of Words, TF-IDF, and word embeddings (Word2Vec, GloVe) were critical in feature extraction. Experimenting with classification techniques such as logistic regression, SVM, and neural networks also helped to develop the model, emphasising the necessity of choosing proper methods and hyperparameter tweaking for successful resume categorisation.\n",
        "Challenges Encountered: Some issues in resume classification were job title ambiguity, where generic professions like \"Consultant\" may span many industries, making categorisation difficult. Handling unstructured data in diverse forms (PDF, Word, and text) provided hurdles for consistent feature extraction. Imbalanced data also resulted in biases, since specific employment types were under-represented, confounding model training. Furthermore, identifying synonyms for comparable abilities or job titles, such as \"Data Scientist\" and \"Data Analyst,\" need considerable attention to assure resume categorisation accuracy.\n",
        "Relevance to field study: This activity is extremely significant to the discipline of NLP, particularly in terms of feature extraction and text categorisation. Resume classification is a real-world challenge in which NLP methods like as tokenisation, named entity identification, and text vectorisation are vital. It is applicable to document categorisation, a popular NLP job, and may be expanded to other domains such as email filtering, sentiment analysis, and chatbot building. By automating the resume screening process, our effort adds to a critical area of NLP applications in the recruiting and HR industries.\n",
        "As I have a background in information science, I can use your knowledge to improve data processing, feature extraction, and model construction, all of which are necessary for developing a strong resume categorisation system.\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "CAq0DZWAhU9m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "a92bb09f-5d36-4180-da29-62b529fe3244"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nPlease write you answer here:\\nLearning experience: Working on resume categorisation has provided valuable expertise in using NLP approaches to extract relevant characteristics from text. Key concepts such as text preprocessing (noise removal, tokenisation, and lemmatisation), Named Entity Recognition (NER) for extracting job titles and degrees, and vectorisation techniques such as Bag of Words, TF-IDF, and word embeddings (Word2Vec, GloVe) were critical in feature extraction. Experimenting with classification techniques such as logistic regression, SVM, and neural networks also helped to develop the model, emphasising the necessity of choosing proper methods and hyperparameter tweaking for successful resume categorisation.\\nChallenges Encountered: Some issues in resume classification were job title ambiguity, where generic professions like \"Consultant\" may span many industries, making categorisation difficult. Handling unstructured data in diverse forms (PDF, Word, and text) provided hurdles for consistent feature extraction. Imbalanced data also resulted in biases, since specific employment types were under-represented, confounding model training. Furthermore, identifying synonyms for comparable abilities or job titles, such as \"Data Scientist\" and \"Data Analyst,\" need considerable attention to assure resume categorisation accuracy.\\nRelevance to field study: This activity is extremely significant to the discipline of NLP, particularly in terms of feature extraction and text categorisation. Resume classification is a real-world challenge in which NLP methods like as tokenisation, named entity identification, and text vectorisation are vital. It is applicable to document categorisation, a popular NLP job, and may be expanded to other domains such as email filtering, sentiment analysis, and chatbot building. By automating the resume screening process, our effort adds to a critical area of NLP applications in the recruiting and HR industries.\\nAs I have a background in information science, I can use your knowledge to improve data processing, feature extraction, and model construction, all of which are necessary for developing a strong resume categorisation system.\\n\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fwd7IhXiCSds"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}