{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sireesha-cloud/Sireesha_INFO5731_Fall2024/blob/main/INFO5731_Exercise_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DymRJbxDBCnf"
      },
      "source": [
        "\n",
        "# **INFO5731 In-class Exercise 2**\n",
        "\n",
        "The purpose of this exercise is to understand users' information needs, and then collect data from different sources for analysis by implementing web scraping using Python.\n",
        "\n",
        "**Expectations**:\n",
        "*   Students are expected to complete the exercise during lecture period to meet the active participation criteria of the course.\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "**Total points**: 40\n",
        "\n",
        "**Deadline**: This in-class exercise is due at the end of the day tomorrow, at 11:59 PM.\n",
        "\n",
        "**Late submissions will have a penalty of 10% of the marks for each day of late submission. , and no requests will be answered. Manage your time accordingly.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1 (10 Points)\n",
        "Describe an interesting research question (or practical question or something innovative) you have in mind, what kind of data should be collected to answer the question(s)? Specify the amount of data needed for analysis. Provide detailed steps for collecting and saving the data."
      ],
      "metadata": {
        "id": "FBKvD6O_TY6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "An interesting topic can be:\"How does remote work impact employee productivity and well-being across different industries?\"\n",
        "\n",
        "1. Details on employee productivity: Keep track of performance data including completed tasks, hours done, project deadlines reached, and work quality. This can be obtained from project management applications (such as Jira and Asana).\n",
        "\n",
        "2. Well-being indicators: Collect self-reported information about job satisfaction, mental health (via surveys), stress levels, and work-life balance. Use standardised well-being measures such as the Warwick-Edinburgh Mental Well-Being Scale.\n",
        "\n",
        "3. Industry context: Gather information on firm size, industry type, and role-specific requirements (via HR databases or industry reports).\n",
        "\n",
        "4. Work environment: Include information on workspace configuration (home vs. office), productivity tool use, and meeting hours (recorded using communication platforms such as Zoom and Slack).\n",
        "\n",
        "Sample Size: Aim for at least 100 organisations from 5 industries.\n",
        "Employee data: Collect data from at least 1,000 employees to ensure representation across roles and seniority levels.\n",
        "\n",
        "Steps for Data collection:\n",
        "Survey distribution: Use a platform like Qualtrics to collect well-being data on a monthly basis for a year.\n",
        "Automated data extraction: Combine project management and communication systems to automatically collect productivity measures.\n",
        "Industry data: Collaborate with HR departments to gather company and role-specific data.\n",
        "Data storage: To preserve privacy, save data on a secure cloud storage (e.g., AWS, Google Cloud) using anonymised employee information.\n",
        "Analysis: Statistical analysis, correlation, and regression models can uncover links between remote work, productivity, and well-being.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FCn9CsP0swSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-4WcJTWSsvxy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2 (10 Points)\n",
        "Write Python code to collect a dataset of 1000 samples related to the question discussed in Question 1."
      ],
      "metadata": {
        "id": "E9RqrlwdTfvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your answer here\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "industries = ['Technology', 'Healthcare', 'Finance', 'Education', 'Manufacturing']\n",
        "job_roles = ['Engineer', 'Manager', 'Analyst', 'Sales', 'Admin']\n",
        "company_sizes = ['Small', 'Medium', 'Large']\n",
        "work_envs = ['Remote', 'In-office', 'Hybrid']\n",
        "\n",
        "\n",
        "def generate_sample():\n",
        "    return {\n",
        "        'Industry': random.choice(industries),\n",
        "        'Job Role': random.choice(job_roles),\n",
        "        'Company Size': random.choice(company_sizes),\n",
        "        'Work Environment': random.choice(work_envs),\n",
        "        'Tasks Completed': np.random.randint(50, 200),  # Simulating tasks per month\n",
        "        'Hours Worked': np.random.randint(120, 200),  # Hours per month\n",
        "        'Deadlines Met': np.random.randint(70, 100),  # Percentage\n",
        "        'Job Satisfaction': np.random.uniform(1, 10),  # Satisfaction score (1-10)\n",
        "        'Stress Level': np.random.uniform(1, 10),  # Stress score (1-10)\n",
        "        'Work-life Balance': np.random.uniform(1, 10),  # Work-life balance score (1-10)\n",
        "        'Meetings Attended': np.random.randint(5, 40),  # Meetings per month\n",
        "    }\n",
        "\n",
        "\n",
        "data = [generate_sample() for _ in range(1000)]\n",
        "\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "df.to_csv('remote_work_productivity_wellbeing_data.csv', index=False)\n",
        "\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "4XvRknixTh1g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "798bdd45-03ad-4cd9-e9df-bcecc6b5e313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Industry  Job Role Company Size Work Environment  Tasks Completed  \\\n",
              "0   Education     Sales        Large        In-office              147   \n",
              "1     Finance  Engineer       Medium        In-office               93   \n",
              "2  Technology     Admin       Medium        In-office               99   \n",
              "3  Healthcare  Engineer        Large           Remote              123   \n",
              "4     Finance   Manager        Small           Hybrid              137   \n",
              "\n",
              "   Hours Worked  Deadlines Met  Job Satisfaction  Stress Level  \\\n",
              "0           193             74          2.566495      7.438610   \n",
              "1           139             90          6.059047      9.755933   \n",
              "2           186             90          3.843047      9.634312   \n",
              "3           156             74          7.841646      7.734121   \n",
              "4           147             82          2.161405      9.176223   \n",
              "\n",
              "   Work-life Balance  Meetings Attended  \n",
              "0           5.756423                 16  \n",
              "1           3.004954                 39  \n",
              "2           8.268379                 34  \n",
              "3           2.589443                 16  \n",
              "4           7.554941                 10  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-52299789-06cc-4a18-8b96-5c0677a5a256\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Industry</th>\n",
              "      <th>Job Role</th>\n",
              "      <th>Company Size</th>\n",
              "      <th>Work Environment</th>\n",
              "      <th>Tasks Completed</th>\n",
              "      <th>Hours Worked</th>\n",
              "      <th>Deadlines Met</th>\n",
              "      <th>Job Satisfaction</th>\n",
              "      <th>Stress Level</th>\n",
              "      <th>Work-life Balance</th>\n",
              "      <th>Meetings Attended</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Education</td>\n",
              "      <td>Sales</td>\n",
              "      <td>Large</td>\n",
              "      <td>In-office</td>\n",
              "      <td>147</td>\n",
              "      <td>193</td>\n",
              "      <td>74</td>\n",
              "      <td>2.566495</td>\n",
              "      <td>7.438610</td>\n",
              "      <td>5.756423</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Finance</td>\n",
              "      <td>Engineer</td>\n",
              "      <td>Medium</td>\n",
              "      <td>In-office</td>\n",
              "      <td>93</td>\n",
              "      <td>139</td>\n",
              "      <td>90</td>\n",
              "      <td>6.059047</td>\n",
              "      <td>9.755933</td>\n",
              "      <td>3.004954</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Technology</td>\n",
              "      <td>Admin</td>\n",
              "      <td>Medium</td>\n",
              "      <td>In-office</td>\n",
              "      <td>99</td>\n",
              "      <td>186</td>\n",
              "      <td>90</td>\n",
              "      <td>3.843047</td>\n",
              "      <td>9.634312</td>\n",
              "      <td>8.268379</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Healthcare</td>\n",
              "      <td>Engineer</td>\n",
              "      <td>Large</td>\n",
              "      <td>Remote</td>\n",
              "      <td>123</td>\n",
              "      <td>156</td>\n",
              "      <td>74</td>\n",
              "      <td>7.841646</td>\n",
              "      <td>7.734121</td>\n",
              "      <td>2.589443</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Finance</td>\n",
              "      <td>Manager</td>\n",
              "      <td>Small</td>\n",
              "      <td>Hybrid</td>\n",
              "      <td>137</td>\n",
              "      <td>147</td>\n",
              "      <td>82</td>\n",
              "      <td>2.161405</td>\n",
              "      <td>9.176223</td>\n",
              "      <td>7.554941</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52299789-06cc-4a18-8b96-5c0677a5a256')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-52299789-06cc-4a18-8b96-5c0677a5a256 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-52299789-06cc-4a18-8b96-5c0677a5a256');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1903e1b9-8ef9-45f5-82f8-42cea5ecb5a8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1903e1b9-8ef9-45f5-82f8-42cea5ecb5a8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1903e1b9-8ef9-45f5-82f8-42cea5ecb5a8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"Industry\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Finance\",\n          \"Manufacturing\",\n          \"Technology\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Job Role\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Engineer\",\n          \"Analyst\",\n          \"Admin\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Company Size\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Large\",\n          \"Medium\",\n          \"Small\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Work Environment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"In-office\",\n          \"Remote\",\n          \"Hybrid\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tasks Completed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 43,\n        \"min\": 50,\n        \"max\": 199,\n        \"num_unique_values\": 150,\n        \"samples\": [\n          72,\n          60,\n          88\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hours Worked\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22,\n        \"min\": 120,\n        \"max\": 199,\n        \"num_unique_values\": 80,\n        \"samples\": [\n          134,\n          193,\n          154\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Deadlines Met\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 70,\n        \"max\": 99,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          88,\n          97,\n          81\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Job Satisfaction\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.533353625695201,\n        \"min\": 1.022730893843864,\n        \"max\": 9.983633223244118,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          3.2650426339852023,\n          4.552104981342946,\n          3.001294512327776\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stress Level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.625317128267428,\n        \"min\": 1.006513173267991,\n        \"max\": 9.997950940247469,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          4.963369868281548,\n          9.921587024605817,\n          6.718163333040297\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Work-life Balance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.5724106062277974,\n        \"min\": 1.0004714934802565,\n        \"max\": 9.999920679148037,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          9.23966097960248,\n          7.797509456302668,\n          1.1302258900215314\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Meetings Attended\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 5,\n        \"max\": 39,\n        \"num_unique_values\": 35,\n        \"samples\": [\n          14,\n          18,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03jb4GZsBkBS"
      },
      "source": [
        "## Question 3 (10 Points)\n",
        "Write Python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/), or ACM Digital Libraries (https://dl.acm.org/) with the keyword \"XYZ\". The articles should be published in the last 10 years (2014-2024).\n",
        "\n",
        "The following information from the article needs to be collected:\n",
        "\n",
        "(1) Title of the article\n",
        "\n",
        "(2) Venue/journal/conference being published\n",
        "\n",
        "(3) Year\n",
        "\n",
        "(4) Authors\n",
        "\n",
        "(5) Abstract"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "def xyz(query, num_articles):\n",
        "    base_url = \"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C44&q=XYZ&btnG=\"\n",
        "    params = {\n",
        "        'hl': 'en',\n",
        "        'q': query,\n",
        "        'as_ylo': '2014',  # From year 2014\n",
        "        'as_yhi': '2024'   # To year 2024\n",
        "    }\n",
        "\n",
        "    response = requests.get(base_url, params=params)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    articles = []\n",
        "\n",
        "    for entry in soup.find_all('div', class_='gs_ri')[:num_articles]:\n",
        "        title_tag = entry.find('h3', class_='gs_rt')\n",
        "        authors_tag = entry.find('div', class_='gs_a')\n",
        "        abstract_tag = entry.find('div', class_='gs_rs')\n",
        "\n",
        "        title = title_tag.text if title_tag else \"N/A\"\n",
        "        venue = authors_tag.text.split('-')[1].strip() if authors_tag and len(authors_tag.text.split('-')) > 1 else \"N/A\"\n",
        "        year = authors_tag.text.split()[-1] if authors_tag else \"N/A\"\n",
        "        authors = ', '.join(authors_tag.text.split('-')[0].split(', ')) if authors_tag else \"N/A\"\n",
        "        abstract = abstract_tag.text if abstract_tag else \"N/A\"\n",
        "\n",
        "        articles.append({'Title': title, 'Venue': venue, 'Year': year, 'Authors': authors, 'Abstract': abstract})\n",
        "\n",
        "    return articles\n",
        "\n",
        "query = \"natural language processing\"\n",
        "articles = xyz(query, 1000)\n",
        "\n",
        "\n",
        "df = pd.DataFrame(articles)\n",
        "df.to_csv('google_scholar_articles.csv', index=False)\n",
        "print(df.head(15))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWN-H4na6VW3",
        "outputId": "8956a157-9ec0-4dc4-aaab-0d50f28bce9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               Title  \\\n",
            "0                        Natural language processing   \n",
            "1  [HTML][HTML] Natural language processing: stat...   \n",
            "2            Advances in natural language processing   \n",
            "3  A primer on neural network models for natural ...   \n",
            "4  [PDF][PDF] The Stanford CoreNLP natural langua...   \n",
            "5  Transformers: State-of-the-art natural languag...   \n",
            "6  [BOOK][B] Neural network methods in natural la...   \n",
            "7  Allennlp: A deep semantic natural language pro...   \n",
            "8  Stanza: A Python natural language processing t...   \n",
            "9  Jumping NLP curves: A review of natural langua...   \n",
            "\n",
            "                                               Venue                 Year  \\\n",
            "0      Fundamentals of artificial intelligence, 2020             Springer   \n",
            "1            Multimedia tools and applications, 2023             Springer   \n",
            "2                                      Science, 2015          science.org   \n",
            "3  Journal of Artificial Intelligence Research, 2016             jair.org   \n",
            "4                        Proceedings of 52nd …, 2014     aclanthology.org   \n",
            "5                      … language processing …, 2020     aclanthology.org   \n",
            "6                                               2017     books.google.com   \n",
            "7                       arXiv preprint arXiv …, 2018            arxiv.org   \n",
            "8                       arXiv preprint arXiv …, 2020            arxiv.org   \n",
            "9            IEEE Computational intelligence …, 2014  ieeexplore.ieee.org   \n",
            "\n",
            "                                     Authors  \\\n",
            "0                KR Chowdhary, KR Chowdhary    \n",
            "1     D Khurana, A Koli, K Khatter, S Singh    \n",
            "2                  J Hirschberg, CD Manning    \n",
            "3                                Y Goldberg    \n",
            "4          CD Manning, M Surdeanu, J Bauer…    \n",
            "5      T Wolf, L Debut, V Sanh, J Chaumond…    \n",
            "6                                Y Goldberg    \n",
            "7  M Gardner, J Grus, M Neumann, O Tafjord…    \n",
            "8         P Qi, Y Zhang, Y Zhang, J Bolton…    \n",
            "9                        E Cambria, B White    \n",
            "\n",
            "                                            Abstract  \n",
            "0  … Python is also available with an extensive s...  \n",
            "1  … in machine specific language, Natural Langua...  \n",
            "2  … Natural language processing employs computat...  \n",
            "3  … More recently, neural network models started...  \n",
            "4  We describe the design and use of the Stanford...  \n",
            "5  … Recent progress in natural language processi...  \n",
            "6  … The series consists of 50- to 150-page monog...  \n",
            "7  This paper describes AllenNLP, a platform for ...  \n",
            "8  … open-source Python natural language processi...  \n",
            "9  … a deep understanding of natural language by ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sBhN5y7r6ow8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJDe71iLB616"
      },
      "source": [
        "## Question 4A (10 Points)\n",
        "Develop Python code to collect data from social media platforms like Reddit, Instagram, Twitter (formerly known as X), Facebook, or any other. Use hashtags, keywords, usernames, or user IDs to gather the data.\n",
        "\n",
        "\n",
        "\n",
        "Ensure that the collected data has more than four columns.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 4B (10 Points)\n",
        "If you encounter challenges with Question-4 web scraping using Python, employ any online tools such as ParseHub or Octoparse for data extraction. Introduce the selected tool, outline the steps for web scraping, and showcase the final output in formats like CSV or Excel.\n",
        "\n",
        "\n",
        "\n",
        "Upload a document (Word or PDF File) in any shared storage (preferably UNT OneDrive) and add the publicly accessible link in the below code cell.\n",
        "\n",
        "Please only choose one option for question 4. If you do both options, we will grade only the first one"
      ],
      "metadata": {
        "id": "4P6-8k0sHJjn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I57NXsauCec2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "bbb25202-ad5c-4c72-da03-6c549f19378a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I used ParseHub to scrape the Reddit data\\nSteps:\\n1. Download parse hub desktop app.\\n2. Created a new project in ParseHub and pasted the Reddit URL.\\n3. Extracted the names and URLs using the ParseHubselection tool.\\n4. Employed relative search to extract the released count of every row.\\n5. Carried out the data scraping to collect the needed information.\\n6. Saved the extracted data in CSV Format.\\n7. The CSV file was transformed into PDF Format. \\n8. PDF Format was uploaded to Google Drive and made it Public to access everyone.\\n\\nLINK : https://myunt-my.sharepoint.com/:b:/g/personal/sireesharusum_my_unt_edu/ETqe-E_NHKZNitc6kvwZWrwBeWiLJGFlWq95TgX024T4eA?e=0UvyNY'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# write your answer here\n",
        "'''I used ParseHub to scrape the Reddit data\n",
        "Steps:\n",
        "1. Download parse hub desktop app.\n",
        "2. Created a new project in ParseHub and pasted the Reddit URL.\n",
        "3. Extracted the names and URLs using the ParseHubselection tool.\n",
        "4. Employed relative search to extract the released count of every row.\n",
        "5. Carried out the data scraping to collect the needed information.\n",
        "6. Saved the extracted data in CSV Format.\n",
        "7. The CSV file was transformed into PDF Format.\n",
        "8. PDF Format was uploaded to Google Drive and made it Public to access everyone.\n",
        "\n",
        "LINK : https://myunt-my.sharepoint.com/:b:/g/personal/sireesharusum_my_unt_edu/EZJV_9TcjU1MrvarjmWPDvgBuE2asNXFtidNBtOtjRKNNw?e=cI1YL0'''\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "przM-em-Gw3j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mandatory Question"
      ],
      "metadata": {
        "id": "sZOhks1dXWEe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important: Reflective Feedback on Web Scraping and Data Collection**\n",
        "\n",
        "\n",
        "\n",
        "Please share your thoughts and feedback on the web scraping and data collection exercises you have completed in this assignment. Consider the following points in your response:\n",
        "\n",
        "\n",
        "\n",
        "Learning Experience: Describe your overall learning experience in working on web scraping tasks. What were the key concepts or techniques you found most beneficial in understanding the process of extracting data from various online sources?\n",
        "\n",
        "\n",
        "\n",
        "Challenges Encountered: Were there specific difficulties in collecting data from certain websites, and how did you overcome them? If you opted for the non-coding option, share your experience with the chosen tool.\n",
        "\n",
        "\n",
        "\n",
        "Relevance to Your Field of Study: How might the ability to gather and analyze data from online sources enhance your work or research?\n",
        "\n",
        "**(no grading of your submission if this question is left unanswered)**"
      ],
      "metadata": {
        "id": "eqmHVEwaWhbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Write your response here.\n",
        "Learning experience: Working on web scraping chores has been a fascinating experience. It taught me about the vastness and structure (or lack thereof) of online data, as well as its potential value when properly extracted and analysed. HTML parsing, XPath/CSS selectors, and API calls were among the key issues discussed. Learning how to explore the structure of online pages, locate the correct data tags, and deal with potential obstructions like CAPTCHA was critical to understanding the complexities of data extraction.\n",
        "Challenges encountered: Collecting data from specific websites offered several difficulties. Websites with dynamic material loaded via JavaScript, for example, were difficult to work with since the data was not immediately available in the HTML. To get around this, I had to use tools like Selenium or Puppeteer to simulate browser activity and retrieve dynamic material.\n",
        "Relevance to my field of study: The capacity to collect and analyse data from online sources is really useful in my field of study. Whether it's market research, trend analysis, or public sentiment analysis, web scraping allows me to access a vast amount of real-time data that can provide deeper insights. The skills I learnt here will help me automate data collecting methods, making it easier to aggregate, analyse, and understand massive datasets for research projects or track critical metrics more efficiently.\n",
        "'''"
      ],
      "metadata": {
        "id": "akAVJn9YBTQT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "FBKvD6O_TY6e",
        "E9RqrlwdTfvl",
        "03jb4GZsBkBS",
        "jJDe71iLB616",
        "55W9AMdXCSpV",
        "4ulBZ6yhCi9F",
        "6SmvS7nSfbj8",
        "sZOhks1dXWEe"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}